_base_ = [
    '../_base_/models/segformer.py',
    '../_base_/datasets/cityscapes_1024x1024_repeat.py',
    '../_base_/default_runtime.py',
    '../_base_/schedules/schedule_160k_adamw.py'
]

# model settings
norm_cfg = dict(type='SyncBN', requires_grad=True)
find_unused_parameters = True
model = dict(
    type='SegLanguage',
    pretrained='../mmsegmentation/segformer.b5.1024x1024.city.160k.pth',
    backbone=dict(
        type='mit_b5',
        style='pytorch'),
    # text_encoder=dict(
    #     type='CLIPTextEncoder',
    #     pretrained='/pretrained/ViT-B-16.pt',
    #     context_length=77,
    #     embed_dim=512,
    #     transformer_width=512,
    #     transformer_heads=8,
    #     transformer_layers=12,
    #     style='pytorch'),
    decode_head=dict(
        type='SegFormerHead',
        in_channels=[64, 128, 320, 512],
        in_index=[0, 1, 2, 3],
        feature_strides=[4, 8, 16, 32],
        channels=128,
        dropout_ratio=0.1,
        num_classes=19,
        norm_cfg=norm_cfg,
        align_corners=False,
        decoder_params=dict(embed_dim=768),
        loss_decode=dict(type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),
    # model training and testing settings
    train_cfg=dict(),
    # test_cfg=dict(mode='whole'))
    test_cfg=dict(mode='slide', crop_size=(1024,1024), stride=(768,768)),
    ft_backbone=False,
    # load_text_embedding='configs/_base_/datasets/text_embedding/voc12_single.npy'
)


